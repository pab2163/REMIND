---
title: "select_emote_words"
output: html_document
date: "2022-10-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(splitstackshape)
library(tidyverse)
library(corrplot)
library(naniar)
library(anticlust)
emote = read_csv('EMOTE_raw.csv')

freq_data = emote %>%
    dplyr::filter(adjective == 1, adim1 != -99) %>%
    dplyr::select(contains('freq'))

freq_data[freq_data == -99] <- NA

freq_data %>%
    naniar::gg_miss_upset()

freq_data %>%
    cor(use = 'pairwise.complete.obs')

emote %>%
    dplyr::filter(adim1!=-99, adim7!=-99) %>%
    ggplot(data = ., aes(x = adim1, y = adim7)) +
    geom_point() +
    labs(x = 'Valence', y = 'Emotionality') +
    geom_smooth(method = 'lm')


emote %>%
    dplyr::filter(adim1!=-99, adim7!=-99) %>%
    ggplot(data = ., aes(x = adim1, y = adim2)) +
    geom_point() +
    labs(x = 'Valence', y = 'Arousal') +
    geom_smooth(method = 'lm')


emote %>%
    dplyr::filter(adim1!=-99, adim7!=-99) %>%
    dplyr::select(contains('adim')) %>%
    cor()
```


```{r}
pos = emote %>%
    dplyr::filter(adjective == 1, adim1 != -99, freq_BNC != -99) %>%
    dplyr::arrange(adim1) %>%
    slice_max(n=250, adim1) %>%
    slice_max(n =200, freq_BNC)


neg = emote %>%
    dplyr::filter(adjective == 1, adim9 != -99, freq_BNC != -99) %>%
    dplyr::arrange(adim9) %>%
    slice_min(n = 250, adim1) %>%
    slice_max(n = 200, freq_BNC)



top_200_each = rbind(pos, neg) %>%
    dplyr::select(word, freq_BNC, valence=adim1) %>%
    mutate(researcher_remove = '')
    


write.csv(top_200_each, file = 'emote_top_200_positive_negative.csv', row.names = FALSE)
```

# Second round 
```{r}
pos2 = emote %>%
    dplyr::filter(adjective == 1, adim1 != -99, freq_BNC != -99, ! word %in% top_200_each$word) %>%
    dplyr::arrange(adim1) %>%
    slice_max(n=250, adim1) %>%
    slice_max(n =200, freq_BNC)


neg2 = emote %>%
    dplyr::filter(adjective == 1, adim9 != -99, freq_BNC != -99, !word %in% top_200_each$word) %>%
    dplyr::arrange(adim9) %>%
    slice_min(n = 250, adim1) %>%
    slice_max(n = 200, freq_BNC)

another_200_each = rbind(pos2, neg2) %>%
    dplyr::select(word, freq_BNC, valence=adim1) %>%
    mutate(researcher_remove = '',
           condition = ifelse(valence >= 4, '+', '-')) 

write.csv(another_200_each, file = 'emote_second_wordset_positive_negative.csv', row.names = FALSE)
```

# Second round with vetting from Mia / Paul

```{r}
r2_mia_paul = readxl::read_excel('emote_second_wordset_positive_negative.xls') %>%
    dplyr::filter(is.na(researcher_remove))

write.csv(r2_mia_paul, file = 'emote_second_pass_paul_mia_selections.csv')

```


# With vetting from Mia Kyler / Paul Bloom
```{r}
top_200_selections = read_csv('emote_top_200_positive_negative_marked.csv') 

top_200_selections = top_200_selections %>%
    mutate(valence_condition = ifelse(valence <4, 'negative', 'positive')) %>%
    dplyr::filter(is.na(researcher_remove), is.na(state_remove)) 

top_240 = top_200_selections %>%
    group_by(valence_condition) %>%
    slice_max(n = 120, order_by = freq_BNC, with_ties = FALSE)

```

# With vetting from Mia Paul Randy David


```{r}
selections = readxl::read_excel('emote_top_200_positive_negative_marked_RPA_DP.xlsx') %>%
    dplyr::filter(is.na(researcher_remove)) %>%
    mutate(valence_abs = abs(valence - 4), round = '1') 

table(selections$...1)

round2 = readxl::read_excel('emote_second_pass_paul_mia_selections.xls') %>%
    dplyr::filter(researcher_remove=='NA') %>%
    mutate(round = '2') %>%
    dplyr::select(-...1, -...7)

round2 = selections %>%
    dplyr:::select(condition = ...1, word, freq_BNC, valence, researcher_remove, round) %>%
    rbind(., round2) %>%
    mutate(valence_abs = abs(valence - 4),
           log_freq = log10(freq_BNC)) %>%
    dplyr::filter(!is.na(word)) %>%
    dplyr::filter(!valence_abs < 1)

round2 = dplyr::left_join(round2, dplyr::select(emote, word, arousal =adim2, emotionality=adim7, meaning=adim5), by= 'word') %>%
    mutate(arousal_abs = abs(arousal-4))

table(round2$condition)

ggplot(round2, aes(x = condition, y = valence_abs)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) 

ggplot(round2, aes(x = condition, y = arousal_abs)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) 

ggplot(round2, aes(x = condition, y = freq_BNC)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) 

cor.test(round2$arousal_abs, round2$valence)


ggplot(round2, aes(x = valence, y = arousal)) +
    geom_point()

# try anticlustering
covariates = dplyr::select(round2,valence_abs, log_freq) %>% mutate_all(scale)

#c = scale(round2[, c("valence", "freq_BNC")])


round2$matches = anticlust::matching(covariates,
                                     match_between = round2$condition == '+',
                                     match_extreme_first=FALSE)


plot_similarity(scale(round2$valence_abs), round2$matches)

final_selection = dplyr::filter(round2, matches <= 120)

summary(lm(data = final_selection, valence_abs ~ condition))
summary(lm(data = final_selection, freq_BNC ~ condition))
summary(lm(data = final_selection, emotionality ~ condition))
summary(lm(data = final_selection, meaning ~ condition))


ggplot(final_selection, aes(x = condition, y = valence_abs)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) +
    labs(y = 'Valence\nDifference from 4 (neutral)')

ggplot(final_selection, aes(x = condition, y = log_freq)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) +
    labs(y = 'Word frequency (per million)') 

ggplot(final_selection, aes(x = condition, y = emotionality)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) +
    labs(y = 'Word frequency (per million)') 

ggplot(final_selection, aes(x = condition, y = meaning)) +
    geom_boxplot(width = 0.1) +
    geom_jitter(width = 0.2) +
    labs(y = 'Understanding of word meaning')
```


# Stratify based on valence (condition - positive vs. negative), valence (within-condition), arousal, freq_BNC

```{r}
top_240 = final_selection %>%
    dplyr::select(word, valence_condition=condition) %>%
    left_join(emote) %>%
    group_by(valence_condition) %>%
    mutate(freq_BNC_strat = ntile(freq_BNC, n = 3)) %>%
    group_by(valence_condition, freq_BNC_strat) %>%
    mutate(valence_strat = ntile(adim1, n = 2)) %>%
    group_by(valence_condition, freq_BNC_strat, valence_strat) %>%
    mutate(arousal_strat = ntile(adim2, n = 2))


set.seed(11291993)

# stratify 20 times, pick the one with the smallest statistical differences between bins
for (i in 1:20){
    strast = stratified(indt = top_240,
                    group = c('valence_condition', 'valence_strat', 'freq_BNC_strat', 'arousal_strat'), size = 5, bothSets = TRUE)

    stratified_sets = rbind(dplyr::mutate(strast$SAMP1, set = 1), dplyr::mutate(strast$SAMP2, set = 2)) %>%
        mutate(iter = i)

    difference_summary = stratified_sets %>%
        pivot_longer(cols = c(freq_BNC, adim1, adim2)) %>%
        group_by(valence_condition, name) %>%
        nest() %>%
        mutate(diff_model = purrr::map(data, ~lm(data = ., value ~ set) %>% broom::tidy())) %>%
        unnest(diff_model) %>%
        dplyr::filter(term == 'set') %>%
        mutate(iter = i)

    if (i == 1){
        many_stratifications = stratified_sets
        many_summaries = difference_summary
    }else{
        many_stratifications = rbind(many_stratifications, stratified_sets)
        many_summaries = rbind(many_summaries, difference_summary)
    }
}

# choose iteration with smallest differences
best_iter = many_summaries %>%
    group_by(iter) %>%
    summarise(mean_pval = mean(p.value)) %>%
    top_n(n = 1, wt = mean_pval)


ggplot(many_summaries, aes(x = factor(iter), y = p.value)) +
    stat_summary(fun.data = mean_cl_boot)

best_stratification = many_stratifications %>%
    dplyr::filter(iter == best_iter$iter[1])


best_stratification = mutate(best_stratification,
                             valence_abs = abs(adim1-4))

ggplot(best_stratification, aes(x = factor(set), y = valence_abs, color = valence_condition)) +
    stat_summary(fun.data = mean_cl_boot)

ggplot(best_stratification, aes(x = factor(set), y = adim1, color = valence_condition)) +
    stat_summary(fun.data = mean_cl_boot)

ggplot(best_stratification, aes(x = factor(set), y = freq_BNC, color = valence_condition)) +
    stat_summary(fun.data = mean_cl_boot)


valence_strat_check = lm(data = best_stratification, freq_BNC ~ valence_condition*set)
summary(valence_strat_check)

# wrute out the stratification to csv
write.csv(best_stratification, file = 'emote_240_words_stratified.csv', row.names = FALSE)
```

# Make many orders across the 4 runs

* Participants with even ID #s will see set1 pre (runs 1-2), set2 post (runs 3-4). Vice versa for participants with odd ID #s
```{r}
run_groups = c(rep(1, 30), rep(2, 30))

for (seed in 1:200){
    set.seed(seed)
    word_shuffle = best_stratification %>%
        dplyr::select(word, valence_condition, set) %>%
        group_by(valence_condition, set) %>%
        mutate(run = sample(run_groups, size = n(), replace = FALSE),
               seed = seed) %>%
        dplyr::mutate(run = case_when(
            seed %% 2 == 0 & run == 1 & set == 1 ~ 1,
            seed %% 2 == 0 & run == 2 & set == 1 ~ 2,
            seed %% 2 == 0 & run == 1 & set == 2 ~ 3,
            seed %% 2 == 0 & run == 2 & set == 2 ~ 4,
            seed %% 2 != 0 & run == 1 & set == 2 ~ 1,
            seed %% 2 != 0 & run == 2 & set == 2 ~  2,
            seed %% 2 != 0 & run == 1 & set == 1 ~ 3,
            seed %% 2 != 0 & run == 2 & set == 1 ~ 4,
        )) %>%
        ungroup() %>%
        dplyr::arrange(run)

    # check that there are 30 words of each valence in each run
    b = table(word_shuffle$run, word_shuffle$valence_condition)
    sum(b == 30)
    assertthat::assert_that(sum(b == 30) == 8, msg = 'Word valence not split evenly across all runs!')

    write.csv(word_shuffle, paste0('word_list_splits/word_order_', seed, '.csv'), row.names = FALSE)
}
```

